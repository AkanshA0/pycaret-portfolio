{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Gradio Demo – Time Series\n",
        "\n",
        "Forecast n steps ahead using a saved univariate time series model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3de7ab66",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transformation Pipeline and Model Successfully Loaded\n",
            "* Running on local URL:  http://127.0.0.1:7866\n",
            "* To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7866/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# app.py\n",
        "# Gradio app for a saved PyCaret anomaly model: iforest_pipeline\n",
        "# Run:\n",
        "#   pip install gradio pandas pycaret\n",
        "#   python app.py\n",
        "\n",
        "import os\n",
        "import tempfile\n",
        "import pandas as pd\n",
        "import gradio as gr\n",
        "\n",
        "# pycaret imports (only what we need)\n",
        "from pycaret.anomaly import load_model, predict_model\n",
        "\n",
        "# ---- load the saved pipeline once at startup ----\n",
        "# Make sure the model files saved via `save_model(model, 'iforest_pipeline')`\n",
        "# are in the working directory, or pass an absolute/relative path without extension.\n",
        "MODEL_NAME = \"iforest_pipeline\"\n",
        "try:\n",
        "    clf = load_model(MODEL_NAME)\n",
        "except Exception as e:\n",
        "    # Surface a clear error early if the file isn't found or is incompatible\n",
        "    raise RuntimeError(\n",
        "        f\"Could not load model '{MODEL_NAME}'. Make sure the saved model files exist \"\n",
        "        f\"and you are using a compatible PyCaret version. Original error: {e}\"\n",
        "    )\n",
        "\n",
        "# Helper: detect likely label/score column names returned by predict_model\n",
        "def _find_col(candidates, cols):\n",
        "    for c in candidates:\n",
        "        if c in cols:\n",
        "            return c\n",
        "    return None\n",
        "\n",
        "def score_csv(file, top_pct):\n",
        "    \"\"\"\n",
        "    file: gr.File (CSV)\n",
        "    top_pct: float (0–50) – highlight top X% highest anomaly scores\n",
        "    \"\"\"\n",
        "    if file is None:\n",
        "        return None, \"Please upload a CSV with the same feature columns used during training.\", None\n",
        "\n",
        "    try:\n",
        "        # Gradio gives a tempfile path; pandas can read it directly\n",
        "        df = pd.read_csv(file.name)\n",
        "    except Exception as e:\n",
        "        return None, f\"❌ Failed to read CSV: {e}\", None\n",
        "\n",
        "    try:\n",
        "        preds = predict_model(clf, data=df.copy())  # non-destructive\n",
        "    except Exception as e:\n",
        "        return None, (\n",
        "            \"❌ predict_model failed. This usually means the CSV columns/types \"\n",
        "            \"don’t match what the pipeline expects.\\n\\n\"\n",
        "            f\"Error: {e}\"\n",
        "        ), None\n",
        "\n",
        "    cols = list(preds.columns)\n",
        "    label_col = _find_col([\"Anomaly\", \"Label\", \"Outlier\", \"anomaly\", \"label\", \"outlier\"], cols)\n",
        "    score_col = _find_col([\"Anomaly_Score\", \"Score\", \"anomaly_score\", \"score\"], cols)\n",
        "\n",
        "    if label_col:\n",
        "        # Map common encodings to boolean-ish, leave others as-is\n",
        "        mapping = {1: True, 0: False, -1: True, \"1\": True, \"0\": False, \"-1\": True, True: True, False: False}\n",
        "        preds[\"is_anomaly\"] = preds[label_col].map(mapping).fillna(preds[label_col])\n",
        "\n",
        "    highlighted = 0\n",
        "    quantile_cut = None\n",
        "    if score_col and top_pct and top_pct > 0:\n",
        "        k = max(1, int(len(preds) * (top_pct / 100.0)))\n",
        "        # Highest scores considered most anomalous (convention in many algorithms; verify for your setup)\n",
        "        ranks = preds[score_col].rank(method=\"first\", ascending=False)\n",
        "        mask_top = ranks <= k\n",
        "        preds[\"TopPctFlag\"] = mask_top\n",
        "        highlighted = int(mask_top.sum())\n",
        "        try:\n",
        "            quantile_cut = float(preds[score_col].quantile(1 - top_pct / 100.0))\n",
        "        except Exception:\n",
        "            quantile_cut = None\n",
        "\n",
        "    # Basic stats\n",
        "    total = len(preds)\n",
        "    anomaly_count = None\n",
        "    if label_col:\n",
        "        anomaly_mask = preds[\"is_anomaly\"].astype(str).isin([\"True\", \"true\", \"1\", \"-1\"])\n",
        "        anomaly_count = int(anomaly_mask.sum())\n",
        "\n",
        "    stats_lines = [f\"**Rows scored:** {total}\"]\n",
        "    if label_col is not None and anomaly_count is not None:\n",
        "        stats_lines.append(f\"**PyCaret-labeled anomalies:** {anomaly_count}\")\n",
        "    if score_col:\n",
        "        stats_lines.append(f\"**Score column:** `{score_col}`\")\n",
        "    if score_col and top_pct and top_pct > 0:\n",
        "        qtxt = f\" ~≥ {quantile_cut:.6g}\" if quantile_cut is not None else \"\"\n",
        "        stats_lines.append(f\"**Top {top_pct:.0f}% score highlight:** {highlighted}{qtxt}\")\n",
        "\n",
        "    # Save a CSV for download\n",
        "    out_path = os.path.join(tempfile.gettempdir(), \"iforest_scored.csv\")\n",
        "    try:\n",
        "        preds.to_csv(out_path, index=False)\n",
        "    except Exception as e:\n",
        "        # If writing fails, still return table + stats\n",
        "        return preds, \"\\n\\n\".join(stats_lines) + f\"\\n\\n⚠️ Could not create download file: {e}\", None\n",
        "\n",
        "    return preds, \"\\n\\n\".join(stats_lines), out_path\n",
        "\n",
        "\n",
        "with gr.Blocks(title=\"PyCaret Anomaly Detector (Isolation Forest)\") as demo:\n",
        "    gr.Markdown(\n",
        "        \"\"\"\n",
        "        # PyCaret Anomaly Detector (Isolation Forest)\n",
        "        Upload a **CSV** with the same features used for training your `iforest_pipeline`.\n",
        "        The app will run `predict_model` and return the predicted anomaly label and score (if available).\n",
        "\n",
        "        **Notes**\n",
        "        - The model is loaded once at startup via `pycaret.anomaly.load_model('iforest_pipeline')`.\n",
        "        - The *Top X% highlight* is a convenience to flag the highest scores for triage; it does **not** alter PyCaret labels.\n",
        "        \"\"\"\n",
        "    )\n",
        "    with gr.Row():\n",
        "        file_in = gr.File(label=\"Upload CSV\", file_types=[\".csv\"])\n",
        "        top_pct = gr.Slider(0, 50, value=5, step=1, label=\"Highlight top X% by score\", info=\"Set to 0 to disable.\")\n",
        "\n",
        "    run_btn = gr.Button(\"Score CSV\", variant=\"primary\")\n",
        "\n",
        "    out_df = gr.Dataframe(label=\"Scored Data\", interactive=False, wrap=True)\n",
        "    out_md = gr.Markdown()\n",
        "    out_file = gr.File(label=\"Download Scored CSV\")\n",
        "\n",
        "    run_btn.click(fn=score_csv, inputs=[file_in, top_pct], outputs=[out_df, out_md, out_file])\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Set share=True if you want a public link\n",
        "    demo.launch()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
